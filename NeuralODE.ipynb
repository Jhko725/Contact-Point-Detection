{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "from cp_detection.NeuralODE import GeneralModeDataset, LightningTrainer\n",
    "from cp_detection.ForceSimulation import ForcedHarmonicOscillator,  SimulateGeneralMode\n",
    "from cp_detection.InteractionForce import DMT_Maugis\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define force model as well as QTF model to be used in simulating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMT = DMT_Maugis(0.2, 10, 2, 130, 1, 0.3, 0.3)\n",
    "ode_params = {'Q':12000, 'A0':1, 'Om':1., 'k':1000}\n",
    "FHO = ForcedHarmonicOscillator(**ode_params, force_model = DMT)\n",
    "#FHO = ForcedHarmonicOscillator(**ode_params, force_model = Null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate general mode approach curve data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d_array = np.linspace(1, 10, 20)\n",
    "t, z_array = SimulateGeneralMode(FHO, d_array, 0.1, 10000, relaxation = 0, rtol = 1e-7)\n",
    "z_array.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "_, ax = plt.subplots(1, 1, figsize = (16, 5))\n",
    "ax.plot(t[-1000:], z_array[0,:], 'k')\n",
    "ax.grid(ls = '--')\n",
    "ax.axvline(x = 5*2*ode_params['Q'], color = 'b')\n",
    "#ax.axvline(x = 10*2*ode_params['Q'], color = 'r')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import json\n",
    "savepath = './Data/transient_test2.json'\n",
    "savedata = {'ode_params':ode_params, 'd_array': d_array.tolist(), 'z_array': z_array.tolist(), 't' : t.tolist()}\n",
    "with open(savepath, 'w') as savefile:\n",
    "    json.dump(savedata, savefile)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "savepath = './Data/digital.json'\n",
    "train_dataset = GeneralModeDataset.load(savepath)\n",
    "train_dataset.t = np.arange(1000)*0.1\n",
    "print(train_dataset.t)\n",
    "train_dataset.save('./Data/digital_fast.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load simulated data and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#savepath = './Data/digital.json'\n",
    "#savepath = './Data/prototype_fake_data.json'\n",
    "#savepath = './Data/digital_snr=1000.json'\n",
    "savepath = './Data/digital_fast.json'\n",
    "hidden_nodes = torch.Tensor([50, 50, 50, 50])\n",
    "train_dataset = GeneralModeDataset.load(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "hparams = Namespace(**{'lr': 0.01, 'batch_size': 20, 'solver': 'rk4', 'fft_loss': False, 'train_dataset_path': savepath, 'hidden_nodes': hidden_nodes})\n",
    "model = LightningTrainer(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([50, 1])\n",
      "<class 'torch.Tensor'> torch.Size([50])\n",
      "<class 'torch.Tensor'> torch.Size([50, 50])\n",
      "<class 'torch.Tensor'> torch.Size([50])\n",
      "<class 'torch.Tensor'> torch.Size([50, 50])\n",
      "<class 'torch.Tensor'> torch.Size([50])\n",
      "<class 'torch.Tensor'> torch.Size([50, 50])\n",
      "<class 'torch.Tensor'> torch.Size([50])\n",
      "<class 'torch.Tensor'> torch.Size([1, 50])\n",
      "<class 'torch.Tensor'> torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhko725/anaconda3/envs/TorchDiff/lib/python3.7/site-packages/pytorch_lightning/utilities/warnings.py:18: UserWarning: Checkpoint directory ./checkpoints exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:VISIBLE GPUS: 0\n",
      "INFO:lightning:\n",
      "  | Name            | Type          | Params\n",
      "----------------------------------------------\n",
      "0 | ODE             | AFM_NeuralODE | 7 K   \n",
      "1 | ODE.Fc          | F_cons        | 7 K   \n",
      "2 | ODE.Fc.layers   | ModuleList    | 7 K   \n",
      "3 | ODE.Fc.layers.0 | Linear        | 100   \n",
      "4 | ODE.Fc.layers.1 | Linear        | 2 K   \n",
      "5 | ODE.Fc.layers.2 | Linear        | 2 K   \n",
      "6 | ODE.Fc.layers.3 | Linear        | 2 K   \n",
      "7 | ODE.Fc.layers.4 | Linear        | 51    \n",
      "8 | ODE.Fc.elu      | ELU           | 0     \n",
      "9 | ODE.Fc.tanh     | Tanh          | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d865b95fc254498cb3f01882746043f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhko725/anaconda3/envs/TorchDiff/lib/python3.7/site-packages/pytorch_lightning/utilities/warnings.py:18: RuntimeWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/jhko725/anaconda3/envs/TorchDiff/lib/python3.7/site-packages/pytorch_lightning/utilities/warnings.py:18: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "INFO:lightning:\n",
      "Epoch 00000: loss reached 0.00009 (best 0.00009), saving model to ./checkpoints/epoch=0_v1.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00001: loss reached 0.00002 (best 0.00002), saving model to ./checkpoints/epoch=1_v0.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00002: loss reached 0.00001 (best 0.00001), saving model to ./checkpoints/epoch=2_v0.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00003: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00004: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00005: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00006: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00007: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=7.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00008: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00009: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00010: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00011: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00012: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00013: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00014: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=14.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00015: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=15.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00016: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00017: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00018: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00019: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00020: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=20.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00021: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=21.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00022: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=22.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00023: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00024: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00025: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00026: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00027: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00028: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=28.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00029: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00030: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00031: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00032: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00033: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00034: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=34.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00035: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=35_v0.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00036: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00037: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00038: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00039: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00040: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00041: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=41.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00042: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=42.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00043: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00044: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00045: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00046: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00047: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=47.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00048: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=48.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00049: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00050: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00051: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00052: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00053: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=53.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00054: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=54.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00055: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=55.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00056: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00057: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=57.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00058: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=58.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00059: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=59.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00060: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=60.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00061: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=61.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00062: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=62.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00063: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00064: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00065: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=65.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00066: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00067: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00068: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=68.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00069: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00070: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=70.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00071: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=71.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00072: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00073: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=73.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00074: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00075: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=75.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00076: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=76.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00077: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=77.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00078: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=78.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00079: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=79.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00080: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=80.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00081: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00082: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=82.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00083: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00084: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00085: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00086: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=86.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00087: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=87.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00088: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=88.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00089: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=89.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00090: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00091: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00092: loss  was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "Epoch 00093: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00094: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=94.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00095: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=95.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00096: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=96.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00097: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=97.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00098: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=98_v0.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00099: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00100: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=100.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00101: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00102: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=102.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00103: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00104: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=104.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00105: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00106: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=106.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00107: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00108: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=108.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00109: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=109.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00110: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=110.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00111: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=111.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00112: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=112.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00113: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=113.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00114: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00115: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=115.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00116: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00117: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=117.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00118: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=118.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00119: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=119.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00120: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=120.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00121: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=121.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00122: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=122.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00123: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=123.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00124: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=124.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00125: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00126: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=126.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00127: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=127.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00128: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=128.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00129: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=129.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00130: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=130.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00131: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=131.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00132: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=132.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00133: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=133.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00134: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=134.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00135: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=135.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00136: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=136_v0.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00137: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=137.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00138: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=138.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00139: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00140: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=140.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00141: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=141.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00142: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=142.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00143: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=143.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00144: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=144.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00145: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=145.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00146: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=146.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00147: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=147.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00148: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=148.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00149: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00150: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00151: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00152: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=152.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00153: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00154: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00155: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=155.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00156: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=156.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00157: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=157.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00158: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00159: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=159.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00160: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00161: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=161.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00162: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=162.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00163: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00164: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=164.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00165: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=165.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00166: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=166.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00167: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=167.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00168: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=168.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00169: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00170: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00171: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=171.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00172: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00173: loss  was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "Epoch 00174: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00175: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00176: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=176.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00177: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00178: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00179: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00180: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00181: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=181.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00182: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00183: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00184: loss  was not in top 1\n",
      "INFO:lightning:\n",
      "Epoch 00185: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=185.ckpt as top 1\n",
      "INFO:lightning:\n",
      "Epoch 00186: loss reached 0.00000 (best 0.00000), saving model to ./checkpoints/epoch=186.ckpt as top 1\n",
      "INFO:lightning:Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.TrainModel(checkpoint_path = './checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model, evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoints/epoch=186.ckpt'\n",
    "#checkpoint_path = './hall_of_fame/20200206/_ckpt_epoch_319.ckpt'\n",
    "model = LightningTrainer.LoadModel(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_array = np.linspace(1, 10, 20)\n",
    "model.cuda()\n",
    "F_pred = model.predict_force(d_array)\n",
    "z_array = np.zeros((2, d_array.size))\n",
    "z_array[1, :] = d_array\n",
    "F_true = DMT(z_array).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (7, 5))\n",
    "ax.plot(d_array, F_pred, '.r', label = 'NN prediction')\n",
    "ax.plot(d_array, F_true, '.k', label = 'True Force')\n",
    "ax.legend()\n",
    "ax.grid(ls = '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]\n",
      " [-0.42603335]]\n"
     ]
    }
   ],
   "source": [
    "print(F_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.47368421,  1.94736842,  2.42105263,  2.89473684,\n",
       "        3.36842105,  3.84210526,  4.31578947,  4.78947368,  5.26315789,\n",
       "        5.73684211,  6.21052632,  6.68421053,  7.15789474,  7.63157895,\n",
       "        8.10526316,  8.57894737,  9.05263158,  9.52631579, 10.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_dataset.d_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "# Remember that you can use make_dot, make_dot_from_trace to get a nice visualization of the model flow\n",
    "# But this does need one epoch of forward propagation, which is extremely costly in the steady state model\n",
    "# The corresponding script to remember is:\n",
    "# make_dot(loss, params=dict(nnode.named_parameters()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
